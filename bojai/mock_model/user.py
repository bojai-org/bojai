from abc import ABC, abstractmethod
import torch
from PIL import Image
from transformers import ViTImageProcessor, BertTokenizer
from model import FineTunedTransformerGEGT

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# userManager: Selects which user (inference logic) to use, based on the task.
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
'''
ğŸ¯ This class exists to pick the correct User class for your pipeline.

Just like how `TrainingManager` picks your Trainer, this picks your model User â€” the component responsible for using your trained model to:
- Accept a user input (text, image, etc.)
- Run it through the model
- Return a clean, readable output

This is called in the deploy stage of your pipeline.

ğŸ§  You can define different "task types" and assign different user logic for each.

Once selected, the `self.user` attribute will be an instance of your custom `User` implementation, ready to use.
'''

class userManager():
    def __init__(self, task_type, model, tokenizer, device, max_length=None):
        self.user = None
        self.tokenizer = tokenizer

        if task_type == '@TODO enter-model-name':
            # Replace the task_type above with your actual model name
            self.user = ImplementYourUser(model, tokenizer, device, max_length)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# User: Abstract class for deploying your model
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
'''
ğŸ§© The `User` class defines how your model is *used* in deployment.

You must extend this class with your own implementation and override `use_model`.

This is NOT training logic â€” itâ€™s how you process live input (from the UI or CLI),
pass it to the model, and return an output.

Use this for:
- Running inference
- Handling post-processing
- Supporting images, text, numbers, files â€” whatever your model uses

ğŸ“¦ You can load the model, apply preprocessing, and return formatted outputs here.
'''

class User(ABC):
    def __init__(self, model, tokenizer, device, max_length):
        super().__init__()
        self.model = model
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.device = device

    @abstractmethod
    def use_model(self, input):
        '''
        input: string, image path, number, or custom data â€” whatever your model expects

        This method should:
        1. Preprocess the input
        2. Run it through the model (using self.model)
        3. Post-process and return the result

        Example (text task):
            tokens = self.tokenizer(input, return_tensors="pt")
            output = self.model(**tokens)
            return output

        Example (image task):
            image = Image.open(input)
            processed = self.processor(image).unsqueeze(0)
            output = self.model(processed)
            return postprocess(output)
        '''
        pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ImplementYourUser: Your own model usage logic
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
'''
âœ… This is where YOU define how your model is used in deployment.

You must extend `User` and implement `use_model`.

You can use:
- Torch
- HuggingFace
- OpenCV
- Pure Python logic
- Anything that fits your model

This class is what the user interacts with during the deploy stage (via UI or CLI).
'''

class ImplementYourUser(User):
    def use_model(self, input):
        '''
        Replace this with your own usage logic.

        Example (for a text model):
            inputs = self.tokenizer(input, return_tensors="pt", padding=True)
            outputs = self.model(**inputs)
            return outputs

        Example (for an image model):
            image = Image.open(input)
            processed = self.processor(image).unsqueeze(0)
            output = self.model(processed)
            return output

        âš ï¸ This must return a value â€” either a string, number, or other result.
        '''
        pass
