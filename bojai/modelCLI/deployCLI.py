import os
import torch
from global_vars import browseDict, getNewModel, getNewTokenizer, hyper_params, task_type
from deploy import Deploy
import sys

def print_header(title):
    print("\n" + "=" * 60)
    print(f"{title}")
    print("=" * 60)

def update_eval_data_cli(deploy):
    print_header("ğŸ“‚ Add New Evaluation Data")
    path = input("Enter path to new evaluation data (file or directory): ").strip()
    if not os.path.exists(path):
        print("âŒ Invalid path.")
        return
    try:
        deploy.update_eval_data(path)
        print("âœ… New evaluation data added.")
    except Exception as e:
        print(f"âŒ Error: {str(e)}")

def evaluate_original_data(deploy):
    print_header("ğŸ“ˆ Evaluate Model on Original Data")
    try:
        score = deploy.get_eval_score(0)
        print(f"âœ… {browseDict['eval_matrice']}: {score}")
    except Exception as e:
        print(f"âŒ Failed to evaluate: {str(e)}")

def evaluate_new_data(deploy):
    if deploy.new_data is None:
        print("âš ï¸  No new evaluation data found.")
        return
    print_header("ğŸ“ˆ Evaluate Model on New Data")
    try:
        score = deploy.get_eval_score(1)
        print(f"âœ… {browseDict['eval_matrice']}: {score}")
    except Exception as e:
        print(f"âŒ Failed to evaluate: {str(e)}")

def use_model_cli(deploy):
    print_header("ğŸ§  Use Model for Inference")
    text_input = input(f"{browseDict['use_model_text']}\n> ").strip()
    try:
        deploy.max_length = 50  # Optional
        output = deploy.use_model(text_input)
        print(f"âœ… Output: {output}")
    except Exception as e:
        print(f"âŒ Inference failed: {str(e)}")

def save_model_cli(deploy):
    print_header("ğŸ’¾ Save Model")
    path = input("Enter directory to save model: ").strip()
    if not os.path.isdir(path):
        print("âŒ Path must be a valid directory.")
        return
    try:
        filename = deploy.trainer.model.__class__.__name__ + ".bin"
        save_path = os.path.join(path, filename)
        torch.save(deploy.trainer.model.state_dict(), save_path)
        print(f"âœ… Model saved to {save_path}")
    except Exception as e:
        print(f"âŒ Error saving model: {str(e)}")

def deploy_cli(deploy : Deploy):
    from trainCLI import train_cli
    from prepareCLI import prepare_cli

    print_header("ğŸš€ Bojai Model Deployment CLI")
    while True:
        print("\nAvailable actions:")
        print("  [a] Add new evaluation data")
        print("  [e] Evaluate on original data")
        if deploy.new_data:
            print("  [n] Evaluate on new data")
        print("  [u] Use model for inference")
        print("  [s] Save model")
        print("  [t] â¬…ï¸  Go back to training")
        print("  [p] â¬…ï¸  Go back to data preparation")
        print("  [q] Quit")

        choice = input("Enter your choice: ").strip().lower()

        if choice == "a":
            update_eval_data_cli(deploy)
        elif choice == "e":
            evaluate_original_data(deploy)
        elif choice == "n" and deploy.new_data:
            evaluate_new_data(deploy)
        elif choice == "u":
            use_model_cli(deploy)
        elif choice == "s":
            save_model_cli(deploy)
        elif choice == "t":
            print("ğŸ” Returning to training CLI...")
            train_cli(deploy.trainer)
            print("âœ… Returned to deployment stage.")
        elif choice == "p":
            print("ğŸ” Returning to data preparation CLI...")
            prepare_cli(deploy.trainer.prep)
            print("âœ… Returned to deployment stage.")
        elif choice == "q":
            print("ğŸ‘‹ Exiting deployment CLI.")
            sys.exit(0)
        else:
            print("âŒ Invalid choice.")



if __name__ == "__main__":
    from prepare import Prepare
    from train import Train
    model_name = ""
    data_address = input("enter dataset address: ")
    training_div = 0.8
    eval_div = 0.2
    tokenizer = getNewTokenizer()
    model = getNewModel()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    prep = Prepare(model_name, model, device, tokenizer, data_address, task_type, (training_div, eval_div), '')
    hyperparams = hyper_params
    train = Train(prep, hyperparams)  
    deploy = Deploy(train, 100)
    deploy_cli(deploy)